# ğŸ¤ Speech Emotion Recognition Web App

A web-based application that identifies emotions from audio files using machine learning. The project classifies audio into one of eight emotions:  
**Angry, Calm, Disgust, Fearful, Happy, Neutral, Sad, Surprised.**

---

## ğŸš€ Live link
ğŸŒ View Deployed App on Streamlit Cloud]](https://eqgcxavrsgmoaxgwxmcubn.streamlit.app(#)  
*(Replace `#` with your actual Streamlit Cloud URL after deployment)*

---

## ğŸ“‚ Project Structure
```text
SER/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ streamlit_app.py      # Streamlit web app
â”‚   â””â”€â”€ utils.py              # Feature extraction and preprocessing
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ SER.keras             # Trained emotion classification model
â”‚   â”œâ”€â”€ scaler.pkl            # Standard Scaler
â”‚   â””â”€â”€ pca.pkl               # PCA transformer
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ SER.ipynb             # Model training and analysis notebook
â”œâ”€â”€ test_model.py             # Test script to check predictions locally
â”œâ”€â”€ requirements.txt          # Project dependencies
â””â”€â”€ README.md                 # Project documentation
```
## ğŸ¯ Objective
To develop a speech emotion recognition system that:
- Accepts `.wav` audio files as input.
- Extracts relevant audio features.
- Predicts the emotional state of the speaker using a trained deep learning model.
- Provides an easy-to-use web interface built with Streamlit.

---

## ğŸ” Methodology

### 1. **Data Preprocessing**
- **Audio Standardization:** All audio files were resampled to a consistent sampling rate.
- **Padding/Clipping:** Ensured all audio files are of uniform duration (3 seconds).
- **Feature Extraction:** Extracted 193 features including:
  - MFCCs
  - Chroma
  - Mel Spectrogram
  - Spectral Contrast
  - Tonnetz

### 2. **Preprocessing Pipeline**
- **Standard Scaler:** Applied to normalize feature scales.
- **PCA (Principal Component Analysis):** Used for dimensionality reduction to improve model performance and reduce overfitting.

### 3. **Model Architecture**
- Deep learning model based on a CNN-BiLSTM-Attention architecture.
- Trained to classify audi

---

## ğŸ“ˆ Model Performance
*(Update these based on your notebook results)*  
- **Training Accuracy:** _Add your training accuracy here_  
- **Validation Accuracy:** _Add your validation accuracy here_

---

## ğŸ› ï¸ Tech Stack
- Python
- TensorFlow / Keras
- Librosa (audio processing)
- Scikit-learn
- Streamlit (web deployment)

---

## ğŸ–¥ï¸ Running the Project Locally

### 1. Clone the repository
```bash
git clone https://github.com/Piyushgoyal-09/SER.git
```
### 2. Install dependencies
```bash
pip install -r requirements.txt
```
### 3. Run the Streamlit app
```bash
streamlit run app/streamlit_app.py
```
